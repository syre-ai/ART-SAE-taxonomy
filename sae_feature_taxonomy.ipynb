{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUIs_w6UZSoc"
   },
   "source": "# ART-Organized SAE Feature Taxonomy\n\nCluster pre-trained SAE decoder weight vectors from **Pythia** models using Adaptive Resonance Theory (ART) modules to build hierarchical feature taxonomies.\n\n**Pipeline:** SAE W_dec → optional PCA → ART clustering → hierarchical taxonomy via SMART\n\n**Key idea:** ART's vigilance parameter provides a single, principled knob for controlling cluster granularity — something SAEs lack. SMART builds a hierarchy by stacking multiple vigilance levels.\n\n**Supported models:** Pythia-70M (512-dim, 32k features), Pythia-410M (1024-dim, 65k features)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FvpA7ONAZSod",
    "outputId": "91fa49ee-f56d-4863-bd01-eccb51a1ebc8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": "# --- Setup ---\nimport sys, os\n\nIN_COLAB = \"google.colab\" in sys.modules\nif IN_COLAB:\n    # Clone or pull the repo, then cd into it\n    if os.path.exists(\"art_utils.py\"):\n        # Already inside the repo (cell re-run)\n        !git pull\n    elif os.path.exists(\"ART-SAE-taxonomy\"):\n        os.chdir(\"ART-SAE-taxonomy\")\n        !git pull\n    else:\n        !git clone https://github.com/syre-ai/ART-SAE-taxonomy.git\n        os.chdir(\"ART-SAE-taxonomy\")\n    !pip install -q artlib==0.1.7 eai-sparsify transformers torch umap-learn plotly tqdm pandas\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom tqdm.auto import tqdm\n\n# Force-reload local modules so git pull changes take effect\nimport importlib\nimport gpu_fuzzy_art, art_utils\nimportlib.reload(gpu_fuzzy_art)\nimportlib.reload(art_utils)\n\nfrom art_utils import (\n    create_art_module,\n    create_smart_model,\n    extract_hierarchy_labels,\n    list_available_modules,\n)\n\nprint(\"Setup complete.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-WJVFqVZSoe"
   },
   "outputs": [],
   "source": "# ============================================================\n# CONFIGURATION — edit this cell to change experiments\n# ============================================================\n\n# --- Model ---\nLM_MODEL = \"EleutherAI/pythia-410m\"     # LM for logit lens interpretation\nSAE_MODEL = \"EleutherAI/sae-pythia-410m-65k\"  # SAE decoder weights to cluster\nLAYER_IDX = 12             # Middle layer (410M has 24 layers, 70M has 6)\n\n# --- Clustering ---\nMODULE_NAME = \"GPUFuzzyART\"  # GPU-accelerated FuzzyART (see list_available_modules())\nPARAM_OVERRIDES = {}       # e.g. {\"rho\": 0.8}\nPCA_DIMS = None            # Set to int (e.g. 50, 100, 200) to reduce dims; None = use raw dims\nQUICK_TEST = True          # Subsample to 1000 features for fast iteration\nRANDOM_SEED = 42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hkGUSk8QZSof",
    "outputId": "51dad020-bd12-4e6f-d265-fbbae5f0f2aa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567,
     "referenced_widgets": [
      "7a769163cb994ee696540defcc9d8004",
      "5a242e5ceeb740c38e63698011acf3ef",
      "d72ee8a8142043ebbeee65093359f5f2",
      "761ec4428f4b4988b8fd52bc70ffb031",
      "d7d7c472c38a4b48be349c63ce78f770",
      "c90b6d555b414422a581c46868e21f3b",
      "b37e81525f1a4e5d9c72df74623abc33",
      "93ee07cbc2f9448fa4f6e76b76f78ae8",
      "7749dfcf282c4a4892d11e87cda41aac",
      "a8f1273328ec49cb9fcbbe4d1148d499",
      "9fb1b49baed04eccb905a69f14afc6e4",
      "5d445b318e01416d8581bbd483e7c834",
      "779842a0a3e84318882b30f4a46822fc",
      "1c61fba917ca465a8c80644c091fce75",
      "8b7c0b01735447538ac73a6c791abeac",
      "37456a9f41144975bb00ad364ebb58f2",
      "8c08137aac294db58eea77f93bc09ac2",
      "2f1111c1450745e9a44fe732351927c2",
      "3bcccf6d8db8493c8f5d500e54650a94",
      "517bbe701d874447a6f2156a65625cb3",
      "b31a19cf294541c7823bd65584dc0aa8",
      "4a8a6f8155b44f81b525c136c7735407"
     ]
    }
   },
   "outputs": [],
   "source": "# --- Load SAE decoder weights ---\nfrom sparsify import Sae\n\nsaes = Sae.load_many(SAE_MODEL)\n\n# Detect key format: \"layers.N\" (70M) vs \"layers.N.mlp\" (410M)\nlayer_key = f\"layers.{LAYER_IDX}\"\nif layer_key not in saes:\n    layer_key = f\"layers.{LAYER_IDX}.mlp\"\nW_dec_raw = saes[layer_key].W_dec.detach().numpy()\nprint(f\"Loaded W_dec from {SAE_MODEL}\")\nprint(f\"  Layer: {layer_key}, shape: {W_dec_raw.shape} (features × hidden_dim)\")\nprint(f\"  Available keys: {sorted(saes.keys())}\")"
  },
  {
   "cell_type": "code",
   "source": "# --- Filter junk features + subsample ---\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\n\n# Load LM (reused by Cell 11 for interpretation)\ntokenizer = AutoTokenizer.from_pretrained(LM_MODEL)\nlm = AutoModelForCausalLM.from_pretrained(LM_MODEL)\nlm.eval()\nlm.float()\n\n# Pythia models have UNTIED embeddings — use embed_out + final_layer_norm\nunembed_weights = lm.embed_out.weight.detach()  # (vocab_size, hidden_dim)\nfinal_ln = lm.gpt_neox.final_layer_norm\nprint(f\"LM: {LM_MODEL}, vocab={unembed_weights.shape[0]}, hidden={unembed_weights.shape[1]}\")\n\n# --- Batch logit lens to classify all features (chunked to avoid OOM) ---\nW_dec_full = torch.from_numpy(W_dec_raw).float()\nn_features = W_dec_full.shape[0]\ntop5_ids = torch.zeros(n_features, 5, dtype=torch.long)\n\nLOGIT_BATCH = 4096\nwith torch.no_grad():\n    for start in range(0, n_features, LOGIT_BATCH):\n        end = min(start + LOGIT_BATCH, n_features)\n        normed = final_ln(W_dec_full[start:end])\n        logits = normed @ unembed_weights.T\n        top5_ids[start:end] = logits.topk(5, dim=1).indices\n        del normed, logits  # free memory between chunks\nprint(f\"Logit lens: computed top-5 tokens for {n_features} features\")\n\n# --- Junk token classifier (minimal: only truly uninformative tokens) ---\ndef is_junk_token(token_id):\n    decoded = tokenizer.decode([token_id])\n    if '\\ufffd' in decoded:        return True   # byte-fallback (broken encoding)\n    if '<|' in decoded:            return True   # special tokens (<|endoftext|> etc.)\n    return False\n\n# Classify each feature: junk if >=3 of top-5 tokens are junk\njunk_counts = torch.zeros(n_features, dtype=torch.long)\nfor i in range(n_features):\n    junk_counts[i] = sum(is_junk_token(tid.item()) for tid in top5_ids[i])\n\nis_junk_feature = junk_counts >= 3  # >=60% junk\nkeep_mask = ~is_junk_feature\n\nn_total = W_dec_raw.shape[0]\nn_kept = keep_mask.sum().item()\nn_filtered = n_total - n_kept\nprint(f\"Junk filter: {n_total} total → {n_kept} kept, {n_filtered} filtered ({n_filtered/n_total:.1%} junk)\")\n\n# Distribution of junk counts\nfor j in range(6):\n    nj = (junk_counts == j).sum().item()\n    print(f\"  {j}/5 junk tokens: {nj} features\")\n\n# --- Apply filter, then subsample/shuffle ---\nkept_indices = torch.where(keep_mask)[0].numpy()\nW_dec_filtered = W_dec_raw[kept_indices]\n\nrng = np.random.default_rng(RANDOM_SEED)\nif QUICK_TEST:\n    n_sample = min(1000, W_dec_filtered.shape[0])\n    idx = rng.choice(W_dec_filtered.shape[0], size=n_sample, replace=False)\n    # Map back to original feature indices\n    idx_original = kept_indices[idx]\n    W_dec = W_dec_filtered[idx]\n    print(f\"\\nQuick test mode: subsampled to {W_dec.shape[0]} features (from {W_dec_filtered.shape[0]} non-junk)\")\nelse:\n    perm = rng.permutation(W_dec_filtered.shape[0])\n    idx_original = kept_indices[perm]\n    W_dec = W_dec_filtered[perm]\n    print(f\"\\nShuffled {W_dec.shape[0]} non-junk features\")\n\n# idx tracks the original feature indices (for logit lens lookups in Cell 11)\nidx = idx_original",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4LIyjTESZSof"
   },
   "outputs": [],
   "source": [
    "# --- Preprocessing: optional PCA (no StandardScaler — W_dec rows are already unit-normalized) ---\n",
    "\n",
    "# Diagnostic: confirm W_dec rows are unit-normalized\n",
    "norms = np.linalg.norm(W_dec, axis=1)\n",
    "print(f\"W_dec L2 norms — min: {norms.min():.4f}, max: {norms.max():.4f}, \"\n",
    "      f\"mean: {norms.mean():.4f}, std: {norms.std():.6f}\")\n",
    "\n",
    "if PCA_DIMS is not None and PCA_DIMS < W_dec.shape[1]:\n",
    "    # PCA centers internally (subtracts mean), which is fine for unit-norm data\n",
    "    pca = PCA(n_components=PCA_DIMS, random_state=RANDOM_SEED)\n",
    "    X_reduced = pca.fit_transform(W_dec)\n",
    "    explained = pca.explained_variance_ratio_.sum()\n",
    "    print(f\"PCA: {W_dec.shape[1]} → {PCA_DIMS} dims ({explained:.1%} variance explained)\")\n",
    "\n",
    "    # Variance diagnostic: dims needed for key thresholds\n",
    "    cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "    for thresh in [0.80, 0.90, 0.95, 0.99]:\n",
    "        n_dims = np.searchsorted(cumvar, thresh) + 1\n",
    "        print(f\"  Dims for {thresh:.0%} variance: {n_dims}\")\n",
    "else:\n",
    "    X_reduced = W_dec.copy()\n",
    "    print(f\"No PCA applied. Using {X_reduced.shape[1]} dims.\")\n",
    "\n",
    "data_dim = X_reduced.shape[1]\n",
    "print(f\"Final data shape: {X_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50u0PNLMZSof"
   },
   "outputs": [],
   "source": [
    "# --- Create ART module ---\n",
    "list_available_modules()\n",
    "print()\n",
    "\n",
    "model = create_art_module(MODULE_NAME, dim=data_dim, overrides=PARAM_OVERRIDES)\n",
    "print(f\"\\nCreated {MODULE_NAME} for {data_dim}-dim data\")\n",
    "print(f\"Parameters: {model.params}\" if hasattr(model, 'params') else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ksj67P6XZSof"
   },
   "outputs": [],
   "source": [
    "# --- Flat clustering ---\n",
    "X_prepared = model.prepare_data(X_reduced)\n",
    "print(f\"Data after prepare_data: shape {X_prepared.shape}\")\n",
    "\n",
    "model.fit(X_prepared, verbose=True)\n",
    "\n",
    "labels = model.labels_\n",
    "n_clusters = model.n_clusters\n",
    "print(f\"\\nClusters found: {n_clusters}\")\n",
    "print(f\"Samples: {len(labels)}\")\n",
    "\n",
    "# Cluster size stats\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(f\"Cluster sizes — min: {counts.min()}, max: {counts.max()}, \"\n",
    "      f\"median: {np.median(counts):.0f}, mean: {counts.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XpMHsmeeZSog"
   },
   "outputs": [],
   "source": [
    "# --- UMAP visualization of flat clusters ---\n",
    "import umap\n",
    "\n",
    "reducer = umap.UMAP(n_components=2, random_state=RANDOM_SEED, n_neighbors=15)\n",
    "embedding = reducer.fit_transform(X_reduced)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(\n",
    "    embedding[:, 0], embedding[:, 1],\n",
    "    c=labels, cmap=\"tab20\", s=5, alpha=0.6\n",
    ")\n",
    "ax.set_title(f\"{MODULE_NAME} Clusters (n={n_clusters}) — UMAP projection\")\n",
    "ax.set_xlabel(\"UMAP 1\")\n",
    "ax.set_ylabel(\"UMAP 2\")\n",
    "plt.colorbar(scatter, ax=ax, label=\"Cluster ID\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZ4bYIZMZSog"
   },
   "outputs": [],
   "source": [
    "# --- Cluster size distribution ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].bar(range(len(counts)), sorted(counts, reverse=True), color=\"steelblue\")\n",
    "axes[0].set_xlabel(\"Cluster rank\")\n",
    "axes[0].set_ylabel(\"Size\")\n",
    "axes[0].set_title(\"Cluster sizes (sorted)\")\n",
    "\n",
    "axes[1].hist(counts, bins=30, color=\"steelblue\", edgecolor=\"white\")\n",
    "axes[1].set_xlabel(\"Cluster size\")\n",
    "axes[1].set_ylabel(\"Count\")\n",
    "axes[1].set_title(\"Cluster size histogram\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZijdnpOZSog"
   },
   "outputs": [],
   "source": "# --- Hierarchical taxonomy with SMART ---\nrho_values = [0.1, 0.4, 0.7]\nsmart = create_smart_model(\n    MODULE_NAME, dim=data_dim, rho_values=rho_values, overrides=PARAM_OVERRIDES\n)\n\nX_smart = smart.prepare_data(X_reduced)\nsmart.fit(X_smart, verbose=True)\n\nhierarchy = extract_hierarchy_labels(smart)\nprint(f\"Hierarchy shape: {hierarchy.shape}  (samples × levels)\")\n\nfor i, rho in enumerate(rho_values):\n    n = len(np.unique(hierarchy[:, i]))\n    print(f\"  Level {i} (rho={rho}): {n} clusters\")"
  },
  {
   "cell_type": "code",
   "source": "# --- Cluster Analysis: specificity, confidence, quality, interpretation ---\n# T1.1: Specificity (bounding box or radius-based)\n# T1.2: Targeted logit lens (tight/distinctive dims)\n# T1.3: Confidence scores (when available)\n# T2.1: Token voting\n# T2.2: Quality metrics (cohesion, silhouette)\n\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom collections import Counter\n\n# ---- Detect module type ----\n_is_gpu_fuzzy = hasattr(smart.modules[0], 'get_bounding_boxes')\n\n# ---- Differential logit lens ----\nglobal_mean_dir = W_dec_full.mean(dim=0)\n\ndef get_cluster_tokens(feature_indices, top_k=10):\n    \"\"\"Differential logit lens: top tokens distinctive to this cluster.\"\"\"\n    dirs = W_dec_full[feature_indices]\n    diff_dir = dirs.mean(dim=0) - global_mean_dir\n    with torch.no_grad():\n        normed = final_ln(diff_dir.unsqueeze(0))\n        logits = (normed @ unembed_weights.T).squeeze(0)\n    topk = logits.topk(top_k)\n    return [tokenizer.decode([tid]) for tid in topk.indices.tolist()]\n\n# ---- Specificity per level ----\nspecificities = {}\nbbox_widths = {}  # Only populated for GPUFuzzyART\n\nfor lv, module in enumerate(smart.modules):\n    if _is_gpu_fuzzy:\n        lower, upper, width = module.get_bounding_boxes()\n        spec = 1.0 - width.mean(dim=1)\n        for cid in sorted(np.unique(hierarchy[:, lv])):\n            specificities[(lv, cid)] = spec[cid].item()\n            bbox_widths[(lv, cid)] = width[cid]\n    else:\n        # HypersphereART / other artlib modules: specificity from radius\n        r_hat = module.params.get('r_hat', 1.0)\n        for cid in sorted(np.unique(hierarchy[:, lv])):\n            if hasattr(module, 'W') and cid < len(module.W):\n                radius = module.W[cid][-1]\n                specificities[(lv, cid)] = max(0.0, 1.0 - radius / r_hat)\n            else:\n                specificities[(lv, cid)] = 0.0\n\nprint(\"Specificity:\")\nfor lv in range(len(rho_values)):\n    specs = [specificities[(lv, c)] for c in sorted(np.unique(hierarchy[:, lv]))]\n    print(f\"  L{lv}: min={min(specs):.3f}, max={max(specs):.3f}, mean={np.mean(specs):.3f}\")\n\n# ---- Confidence scores per level ----\nconfidence = {}\nfor lv, module in enumerate(smart.modules):\n    if _is_gpu_fuzzy:\n        labels_lv, match_lv, margin_lv = module.predict_with_confidence(X_smart)\n        confidence[lv] = (labels_lv, match_lv, margin_lv)\n        print(f\"Confidence L{lv}: M=[{match_lv.min():.3f}, {match_lv.max():.3f}], \"\n              f\"mean T-margin={margin_lv.mean():.4f}\")\n    else:\n        labels_lv = module.labels_\n        confidence[lv] = (labels_lv, None, None)\n        print(f\"Confidence L{lv}: {module.n_clusters} clusters (match/margin N/A for artlib modules)\")\n\n# ---- Cohesion + silhouette ----\ncohesions = {}\nfor lv in range(len(rho_values)):\n    for c in sorted(np.unique(hierarchy[:, lv])):\n        mask = hierarchy[:, lv] == c\n        n = mask.sum()\n        if n < 2:\n            cohesions[(lv, c)] = 1.0\n            continue\n        cluster_data = X_reduced[mask]\n        if n > 500:\n            sub = np.random.choice(n, 500, replace=False)\n            cluster_data = cluster_data[sub]\n        sim = cosine_similarity(cluster_data)\n        k = len(cluster_data)\n        cohesions[(lv, c)] = float((sim.sum() - k) / (k * (k - 1)))\n\nsil_scores = {}\nfor lv in range(len(rho_values)):\n    n_unique = len(np.unique(hierarchy[:, lv]))\n    if n_unique > 1:\n        sil = silhouette_score(\n            X_reduced, hierarchy[:, lv], metric='cosine',\n            sample_size=min(5000, len(X_reduced))\n        )\n        sil_scores[lv] = sil\n        print(f\"Silhouette L{lv} (cosine): {sil:.3f}\")\n\n# ---- Token voting (unfiltered — all tokens contribute) ----\ndef get_cluster_token_votes(feature_indices, top_k=10):\n    \"\"\"Count per-feature top-5 logit lens tokens across cluster.\"\"\"\n    counter = Counter()\n    for fi in feature_indices:\n        for tid in top5_ids[fi].tolist():\n            counter[tid] += 1\n    return [(tokenizer.decode([tid]).strip(), cnt) for tid, cnt in counter.most_common(top_k)]\n\n# ---- Targeted logit lens via selective dimensions ----\ndef get_cluster_tokens_targeted(feature_indices, level, cluster_id, top_k=10, n_tight=100):\n    \"\"\"Project through the most selective dimensions.\"\"\"\n    if (level, cluster_id) in bbox_widths:\n        # GPUFuzzyART: use tightest bounding box dimensions\n        width = bbox_widths[(level, cluster_id)]\n        tight_dims = width.argsort()[:n_tight]\n    else:\n        # HypersphereART/other: use dims where cluster mean deviates most from global mean\n        dirs = W_dec_full[feature_indices]\n        mean_dir = dirs.mean(dim=0)\n        deviation = (mean_dir - global_mean_dir).abs()\n        tight_dims = deviation.argsort(descending=True)[:n_tight]\n\n    dirs = W_dec_full[feature_indices]\n    mean_dir = dirs.mean(dim=0)\n    masked_dir = torch.zeros_like(mean_dir)\n    masked_dir[tight_dims] = mean_dir[tight_dims]\n\n    with torch.no_grad():\n        normed = final_ln(masked_dir.unsqueeze(0))\n        logits = (normed @ unembed_weights.T).squeeze(0)\n    topk = logits.topk(top_k)\n    return [tokenizer.decode([tid]) for tid in topk.indices.tolist()]\n\n# ---- Scatter plot: size vs specificity + size vs cohesion ----\nl0_ids_plot = sorted(np.unique(hierarchy[:, 0]))\nsizes = [np.sum(hierarchy[:, 0] == c) for c in l0_ids_plot]\nspecs_plot = [specificities[(0, c)] for c in l0_ids_plot]\ncohs_plot = [cohesions[(0, c)] for c in l0_ids_plot]\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 4))\naxes[0].scatter(sizes, specs_plot, c='steelblue', s=60, edgecolors='k', linewidths=0.5)\nfor c, s, sp in zip(l0_ids_plot, sizes, specs_plot):\n    axes[0].annotate(f'L0:{c}', (s, sp), fontsize=8, ha='left', va='bottom')\naxes[0].set_xlabel('Cluster size')\naxes[0].set_ylabel('Specificity')\naxes[0].set_title('L0: Size vs Specificity')\naxes[0].grid(True, alpha=0.3)\n\naxes[1].scatter(sizes, cohs_plot, c='coral', s=60, edgecolors='k', linewidths=0.5)\nfor c, s, co in zip(l0_ids_plot, sizes, cohs_plot):\n    axes[1].annotate(f'L0:{c}', (s, co), fontsize=8, ha='left', va='bottom')\naxes[1].set_xlabel('Cluster size')\naxes[1].set_ylabel('Cohesion (mean cosine sim)')\naxes[1].set_title('L0: Size vs Cohesion')\naxes[1].grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nAnalysis setup complete.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# --- L0 Taxonomy with enriched metrics ---\nn_levels = hierarchy.shape[1]\nl0_ids = sorted(np.unique(hierarchy[:, 0]))\n_, l0_match, l0_margin = confidence[0]\n\nprint(\"=\" * 85)\nprint(f\"LEVEL 0 — {len(l0_ids)} broad themes (rho={rho_values[0]})\")\nif 0 in sil_scores:\n    print(f\"Global silhouette (cosine): {sil_scores[0]:.3f}\")\nprint(\"=\" * 85)\n\nfor c in l0_ids:\n    mask = hierarchy[:, 0] == c\n    n_feat = mask.sum()\n    feature_indices = idx[mask]\n\n    # Children count\n    child_info = \"\"\n    if n_levels > 1:\n        n_l1 = len(np.unique(hierarchy[mask, 1]))\n        child_info = f\", {n_l1} L1 children\"\n\n    # Metrics\n    spec = specificities[(0, c)]\n    coh = cohesions[(0, c)]\n\n    # Three interpretation methods\n    diff_tokens = get_cluster_tokens(feature_indices, top_k=15)\n    votes = get_cluster_token_votes(feature_indices, top_k=10)\n    targeted = get_cluster_tokens_targeted(feature_indices, level=0, cluster_id=c, top_k=10)\n\n    print(f\"\\nL0:{c} ({n_feat} features{child_info}):\")\n    metric_parts = [f\"Spec: {spec:.3f}\", f\"Cohesion: {coh:.3f}\"]\n    if l0_match is not None:\n        m_vals = l0_match[mask]\n        t_vals = l0_margin[mask]\n        metric_parts.append(f\"Match: {m_vals.mean():.3f} (min {m_vals.min():.3f})\")\n        metric_parts.append(f\"T-margin: {t_vals.mean():.4f}\")\n    print(f\"  {'  |  '.join(metric_parts)}\")\n    print(f\"  Differential: {diff_tokens}\")\n    print(f\"  Votes:        {', '.join(f'{t}({cnt})' for t, cnt in votes)}\")\n    print(f\"  Targeted:     {targeted}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ueLAu-g7ZSog"
   },
   "outputs": [],
   "source": "# --- Explore hierarchy: drill into any cluster's children ---\n\ndef explore_cluster(level, cluster_id, top_k=10, max_children=50):\n    \"\"\"Show enriched metrics for a cluster and list its children.\"\"\"\n    mask = hierarchy[:, level] == cluster_id\n    n = mask.sum()\n    if n == 0:\n        print(f\"No samples in L{level} cluster {cluster_id}\")\n        return\n\n    feature_indices = idx[mask]\n    diff_tokens = get_cluster_tokens(feature_indices, top_k=top_k)\n    votes = get_cluster_token_votes(feature_indices, top_k=top_k)\n    targeted = get_cluster_tokens_targeted(\n        feature_indices, level=level, cluster_id=cluster_id, top_k=top_k\n    )\n\n    spec = specificities.get((level, cluster_id), 0)\n    coh = cohesions.get((level, cluster_id), 0)\n    _, m_all, t_all = confidence[level]\n\n    print(f\"L{level}:{cluster_id} ({n} features, rho={rho_values[level]}):\")\n    metric_parts = [f\"Spec: {spec:.3f}\", f\"Cohesion: {coh:.3f}\"]\n    if m_all is not None:\n        m_vals = m_all[mask]\n        t_vals = t_all[mask]\n        metric_parts.append(f\"Match: {m_vals.mean():.3f} (min {m_vals.min():.3f})\")\n        metric_parts.append(f\"T-margin: {t_vals.mean():.4f}\")\n    print(f\"  {'  |  '.join(metric_parts)}\")\n    print(f\"  Differential: {diff_tokens}\")\n    print(f\"  Votes:        {', '.join(f'{t}({cnt})' for t, cnt in votes)}\")\n    print(f\"  Targeted:     {targeted}\")\n\n    child_level = level + 1\n    if child_level >= hierarchy.shape[1]:\n        print(\"  (finest level — no children)\")\n        return\n\n    child_ids, child_counts = np.unique(hierarchy[mask, child_level], return_counts=True)\n    order = np.argsort(-child_counts)\n    print(f\"\\n  -> {len(child_ids)} children at L{child_level} (rho={rho_values[child_level]}):\\n\")\n\n    for rank, ci in enumerate(order[:max_children]):\n        cid = child_ids[ci]\n        child_mask = mask & (hierarchy[:, child_level] == cid)\n        child_features = idx[child_mask]\n        child_diff = get_cluster_tokens(child_features, top_k=top_k)\n        child_votes = get_cluster_token_votes(child_features, top_k=5)\n        child_spec = specificities.get((child_level, cid), 0)\n        child_coh = cohesions.get((child_level, cid), 0)\n        vote_str = ', '.join(f'{t}({cnt})' for t, cnt in child_votes[:5])\n        print(f\"    L{child_level}:{cid} ({child_counts[ci]} feat, \"\n              f\"spec={child_spec:.3f}, coh={child_coh:.3f}): {child_diff}\")\n        print(f\"      Votes: {vote_str}\")\n\n    if len(child_ids) > max_children:\n        print(f\"    ... and {len(child_ids) - max_children} more\")\n\n\n# Example: explore Level 0, Cluster 0 — change these to explore different parts\nexplore_cluster(level=0, cluster_id=0)\n\n# To drill deeper, call again with a child:\n# explore_cluster(level=1, cluster_id=<child_id_from_above>)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhqQHZC4ZSoh"
   },
   "outputs": [],
   "source": [
    "# --- Vigilance parameter sweep (optional/advanced) ---\n",
    "# Sweep rho to see how cluster count changes with vigilance.\n",
    "# Higher rho → more clusters (tighter match required, except BayesianART).\n",
    "\n",
    "rho_sweep = np.linspace(0.1, 0.95, 10)\n",
    "cluster_counts = []\n",
    "\n",
    "for rho in tqdm(rho_sweep, desc=\"Vigilance sweep\"):\n",
    "    overrides_sweep = dict(PARAM_OVERRIDES, rho=rho)\n",
    "    m = create_art_module(MODULE_NAME, dim=data_dim, overrides=overrides_sweep)\n",
    "    X_p = m.prepare_data(X_reduced)\n",
    "    m.fit(X_p)\n",
    "    cluster_counts.append(m.n_clusters)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.plot(rho_sweep, cluster_counts, \"o-\", color=\"steelblue\")\n",
    "ax.set_xlabel(\"Vigilance (rho)\")\n",
    "ax.set_ylabel(\"Number of clusters\")\n",
    "ax.set_title(f\"Vigilance sweep — {MODULE_NAME}\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for rho, nc in zip(rho_sweep, cluster_counts):\n",
    "    print(f\"  rho={rho:.2f} → {nc} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBlRV1R6ZSoh"
   },
   "source": [
    "## Phase 2: Checkpoint Comparison (Stub)\n",
    "\n",
    "**Goal:** Track how SAE feature categories evolve across Pythia-70M training checkpoints.\n",
    "\n",
    "**Approach:**\n",
    "1. Load Pythia-70M at multiple checkpoints (e.g., steps 1000, 10000, 50000, 143000)\n",
    "2. Extract SAE decoder weights at each checkpoint\n",
    "3. Use ART's `partial_fit()` to incrementally update the taxonomy\n",
    "4. Track: resonant features (stable), new categories (plastic), dormant categories (lost)\n",
    "\n",
    "This leverages ART's core strength — stability-plasticity balance — which SAEs lack entirely (they must retrain from scratch).\n",
    "\n",
    "*Implementation in Phase 2.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "7a769163cb994ee696540defcc9d8004": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a242e5ceeb740c38e63698011acf3ef",
       "IPY_MODEL_d72ee8a8142043ebbeee65093359f5f2",
       "IPY_MODEL_761ec4428f4b4988b8fd52bc70ffb031"
      ],
      "layout": "IPY_MODEL_d7d7c472c38a4b48be349c63ce78f770"
     }
    },
    "5a242e5ceeb740c38e63698011acf3ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c90b6d555b414422a581c46868e21f3b",
      "placeholder": "​",
      "style": "IPY_MODEL_b37e81525f1a4e5d9c72df74623abc33",
      "value": "Download complete: "
     }
    },
    "d72ee8a8142043ebbeee65093359f5f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93ee07cbc2f9448fa4f6e76b76f78ae8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7749dfcf282c4a4892d11e87cda41aac",
      "value": 1
     }
    },
    "761ec4428f4b4988b8fd52bc70ffb031": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8f1273328ec49cb9fcbbe4d1148d499",
      "placeholder": "​",
      "style": "IPY_MODEL_9fb1b49baed04eccb905a69f14afc6e4",
      "value": " 2.42G/? [00:40&lt;00:00, 128MB/s]"
     }
    },
    "d7d7c472c38a4b48be349c63ce78f770": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c90b6d555b414422a581c46868e21f3b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b37e81525f1a4e5d9c72df74623abc33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93ee07cbc2f9448fa4f6e76b76f78ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "7749dfcf282c4a4892d11e87cda41aac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a8f1273328ec49cb9fcbbe4d1148d499": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fb1b49baed04eccb905a69f14afc6e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d445b318e01416d8581bbd483e7c834": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_779842a0a3e84318882b30f4a46822fc",
       "IPY_MODEL_1c61fba917ca465a8c80644c091fce75",
       "IPY_MODEL_8b7c0b01735447538ac73a6c791abeac"
      ],
      "layout": "IPY_MODEL_37456a9f41144975bb00ad364ebb58f2"
     }
    },
    "779842a0a3e84318882b30f4a46822fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8c08137aac294db58eea77f93bc09ac2",
      "placeholder": "​",
      "style": "IPY_MODEL_2f1111c1450745e9a44fe732351927c2",
      "value": "Fetching 38 files: 100%"
     }
    },
    "1c61fba917ca465a8c80644c091fce75": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bcccf6d8db8493c8f5d500e54650a94",
      "max": 38,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_517bbe701d874447a6f2156a65625cb3",
      "value": 38
     }
    },
    "8b7c0b01735447538ac73a6c791abeac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b31a19cf294541c7823bd65584dc0aa8",
      "placeholder": "​",
      "style": "IPY_MODEL_4a8a6f8155b44f81b525c136c7735407",
      "value": " 38/38 [00:25&lt;00:00,  2.05it/s]"
     }
    },
    "37456a9f41144975bb00ad364ebb58f2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c08137aac294db58eea77f93bc09ac2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f1111c1450745e9a44fe732351927c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3bcccf6d8db8493c8f5d500e54650a94": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "517bbe701d874447a6f2156a65625cb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b31a19cf294541c7823bd65584dc0aa8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a8a6f8155b44f81b525c136c7735407": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}